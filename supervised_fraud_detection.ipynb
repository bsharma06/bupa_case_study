{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Supervised Fraud Detection\n",
        "\n",
        "This notebook builds and evaluates a supervised machine learning model to predict fraudulent payments using the `fraud_cases_master.csv` dataset. The objective is to leverage labeled data to identify patterns indicative of fraud and to assess the model's ability to accurately classify fraudulent transactions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Loading and Preparation\n",
        "\n",
        "We load the `fraud_cases_master.csv` dataset, which includes a `Fraud flag` column indicating fraudulent transactions. Date columns are converted to datetime objects, and `time_to_payment` is calculated as a potential feature. Missing values in numerical columns are filled with the median, and categorical columns with the mode. The `Fraud flag` is our target variable (y).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "try:\n",
        "    df_fraud = pd.read_csv('fraud_cases_master.csv')\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: fraud_cases_master.csv not found. Please ensure the file is in the correct directory.\")\n",
        "    exit()\n",
        "\n",
        "# Convert date columns to datetime objects if needed (for potential feature engineering later)\n",
        "date_cols = ['Date received', 'Date of invoice', 'Date of authorisation', 'Payment due date', 'Date of payment']\n",
        "for col in date_cols:\n",
        "    if col in df_fraud.columns:\n",
        "        df_fraud[col] = pd.to_datetime(df_fraud[col], errors='coerce')\n",
        "\n",
        "# Calculate 'time to payment' as a potential feature\n",
        "df_fraud['time_to_payment'] = (df_fraud['Date of payment'] - df_fraud['Date received']).dt.days\n",
        "\n",
        "# Drop original date columns as we have 'time_to_payment'\n",
        "df_fraud = df_fraud.drop(columns=date_cols, errors='ignore')\n",
        "\n",
        "# Handle potential missing values (e.g., for 'time_to_payment') before splitting\n",
        "df_fraud.dropna(subset=['time_to_payment'], inplace=True)\n",
        "\n",
        "X = df_fraud.drop('Fraud flag', axis=1)\n",
        "y = df_fraud['Fraud flag']\n",
        "\n",
        "print(f\"Dataset loaded with {len(df_fraud)} records after preprocessing.\")\n",
        "print(df_fraud.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Feature Engineering and Preprocessing\n",
        "\n",
        "We define numerical and categorical features for our model. Similar to the regression analysis, numerical features are scaled using `StandardScaler` and categorical features are one-hot encoded using `OneHotEncoder`. The data is then split into training and testing sets, with stratification to ensure a balanced representation of fraudulent and non-fraudulent cases in both sets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Identify categorical and numerical features for preprocessing\n",
        "categorical_features = ['Research team', 'Type of expense', 'Company', 'Payment Status', 'Submitted by', 'Authorised by', 'Payment authoriser']\n",
        "numerical_features = ['Invoice value', 'Payment amount', 'time_to_payment']\n",
        "\n",
        "# Ensure all features exist in X, filter if not\n",
        "categorical_features = [f for f in categorical_features if f in X.columns]\n",
        "numerical_features = [f for f in numerical_features if f in X.columns]\n",
        "\n",
        "X = X[categorical_features + numerical_features]\n",
        "\n",
        "# Preprocessing pipelines for numerical and categorical features\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Create a preprocessor using ColumnTransformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y) # Stratify for imbalanced classes\n",
        "\n",
        "print(\"Data split into training and testing sets with stratification.\")\n",
        "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Model Training and Evaluation\n",
        "\n",
        "We build a `Pipeline` that combines the preprocessing steps with a `RandomForestClassifier`. The model is trained on the preprocessed training data, and then predictions are made on the test set. We evaluate the model using:\n",
        "*   **Accuracy**\n",
        "*   **Confusion Matrix:** To understand true positives, true negatives, false positives, and false negatives.\n",
        "*   **Classification Report:** Providing Precision, Recall, and F1-score for each class.\n",
        "*   **ROC-AUC Score:** To assess the model's ability to distinguish between classes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the model pipeline\n",
        "model_fraud = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                                ('classifier', RandomForestClassifier(random_state=42))])\n",
        "\n",
        "# Train the model\n",
        "model_fraud.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model_fraud.predict(X_test)\n",
        "y_pred_proba = model_fraud.predict_proba(X_test)[:, 1] # Probability for ROC-AUC\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"\\n--- Supervised Model Evaluation for Fraud Detection ---\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "print(f\"ROC-AUC Score: {roc_auc:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
