{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Regression Analysis for Payment Time Prediction\n",
        "\n",
        "Regression analysis to predict the time it takes for invoices to be paid using the `payments_master.csv` dataset. The goal is to understand factors influencing payment duration and to test the hypothesis that all invoices take approximately the same time (±1 day) to be paid.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Loading and Preparation\n",
        "\n",
        "First, we load the `payments_master.csv` dataset and perform initial data cleaning and feature engineering. We convert relevant date columns to datetime objects and calculate the `time_to_payment` in days, which will be our target variable. Rows with missing `time_to_payment` values are dropped.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data directory is set to: c:\\Users\\homep\\Documents\\Projects\\bupa_case_study\\data\n",
            "************************\n",
            "\n",
            "Payment master path: c:\\Users\\homep\\Documents\\Projects\\bupa_case_study\\data\\payments_master.csv\n",
            "Fraud case master path: c:\\Users\\homep\\Documents\\Projects\\bupa_case_study\\data\\fraud_case_master.csv\n",
            "Research team master path: c:\\Users\\homep\\Documents\\Projects\\bupa_case_study\\data\\research_team_master.csv\n",
            "Research team member master path: c:\\Users\\homep\\Documents\\Projects\\bupa_case_study\\data\\research_team_member_master.csv\n"
          ]
        }
      ],
      "source": [
        "cwd = os.getcwd()\n",
        "data_dir = os.path.join(cwd, 'data')\n",
        "print(f\"Data directory is set to: {data_dir}\")\n",
        "\n",
        "payment_master_path = os.path.join(data_dir, 'payments_master.csv')\n",
        "fraud_case_master_path = os.path.join(data_dir, 'fraud_case_master.csv')\n",
        "research_team_master_path = os.path.join(data_dir, 'research_team_master.csv')\n",
        "research_team_member_master_path = os.path.join(data_dir, 'research_team_member_master.csv')\n",
        "print(\"************************\\n\")\n",
        "print(f\"Payment master path: {payment_master_path}\")\n",
        "print(f\"Fraud case master path: {fraud_case_master_path}\")\n",
        "print(f\"Research team master path: {research_team_master_path}\")\n",
        "print(f\"Research team member master path: {research_team_member_master_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset loaded with 1428 records after dropping rows with missing time_to_payment.\n",
            "  Date received Research team        Submitted by Date of invoice  \\\n",
            "0    2025-04-27      Genetics       Melinda White      2025-04-14   \n",
            "1    2025-06-02    Immunology     Daniel Peterson      2025-05-28   \n",
            "3    2025-04-10      Oncology  Christopher Wilson      2025-03-27   \n",
            "4    2025-05-18    Immunology      Amanda Johnson      2025-05-11   \n",
            "5    2025-02-02    Immunology        Austin Terry      2025-01-22   \n",
            "\n",
            "  Invoice number                               Description of spend  \\\n",
            "0      INV-76915  \"Procured DNA extraction kits for isolating hi...   \n",
            "1      INV-64102  \"Purchase of endotoxin-free reagents for in vi...   \n",
            "3      INV-20676  \"Procured RNA extraction kits for high-through...   \n",
            "4      INV-49709  \"Purchased Luminex multiplex assay kits for si...   \n",
            "5      INV-95698  \"Procured reagents for intracellular cytokine ...   \n",
            "\n",
            "   Invoice value Date of authorisation     Authorised by Payment due date  \\\n",
            "0       13319.94            2025-05-11        Kevin Ross       2025-06-09   \n",
            "1       14696.98            2025-06-14     Sarah Collins       2025-07-06   \n",
            "3       13541.31            2025-04-14  Gabriel Sullivan       2025-05-25   \n",
            "4         524.33            2025-06-01    Amanda Johnson       2025-06-29   \n",
            "5       13570.48            2025-02-10     Sarah Collins       2025-03-17   \n",
            "\n",
            "  Date of payment  Payment amount Payment authoriser Payment Status  \\\n",
            "0      2025-05-29        13319.94     Antonio Wilson           Paid   \n",
            "1      2025-06-22        14696.98     Antonio Wilson           Paid   \n",
            "3      2025-04-15        13541.31     Antonio Wilson           Paid   \n",
            "4      2025-06-19          524.33         Robert Day           Paid   \n",
            "5      2025-02-18        13570.48     Antonio Wilson           Paid   \n",
            "\n",
            "     Type of expense                     Company        phone_number  \\\n",
            "0  Software Licenses           IG Group Holdings  (624)900-2038x3126   \n",
            "1     Clinical Trial             Workspace Group          3967724119   \n",
            "3             Travel  Paragon Group of Companies       (550)786-1626   \n",
            "4             Travel         Dunelm Group PLCShs  980-935-3357x69435   \n",
            "5     Clinical Trial        QinetiQ Group PLCShs    920-735-6382x374   \n",
            "\n",
            "                   email  time_to_payment  \n",
            "0          uayers@ig.com             32.0  \n",
            "1   jose87@workspace.com             20.0  \n",
            "3   lauren09@paragon.com              5.0  \n",
            "4    justin02@dunelm.com             32.0  \n",
            "5  anthony02@qinetiq.com             16.0  \n"
          ]
        }
      ],
      "source": [
        "# Load the dataset\n",
        "try:\n",
        "    df = pd.read_csv(payment_master_path)\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: payments_master.csv not found. Please ensure the file is in the correct directory.\")\n",
        "    exit()\n",
        "\n",
        "# Convert date columns to datetime objects\n",
        "date_cols = ['Date received', 'Date of invoice', 'Date of authorisation', 'Payment due date', 'Date of payment']\n",
        "for col in date_cols:\n",
        "    df[col] = pd.to_datetime(df[col], errors='coerce')\n",
        "\n",
        "# Calculate 'time to payment' in days\n",
        "df['time_to_payment'] = (df['Date of payment'] - df['Date received']).dt.days\n",
        "\n",
        "# Drop rows where 'time_to_payment' is NaN (due to missing date of payment or date received)\n",
        "df.dropna(subset=['time_to_payment'], inplace=True)\n",
        "\n",
        "print(f\"Dataset loaded with {len(df)} records after dropping rows with missing time_to_payment.\")\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Feature Selection and Data Preprocessing\n",
        "\n",
        "We select relevant features for our regression model, including numerical features like 'Invoice value' and 'Payment amount', and categorical features such as 'Research team', 'Type of expense', and 'Company'. The target variable is `time_to_payment`.\n",
        "\n",
        "To prepare the data for the model, we use `ColumnTransformer` within a `Pipeline`:\n",
        "*   **Numerical features** are scaled using `StandardScaler`.\n",
        "*   **Categorical features** are one-hot encoded using `OneHotEncoder`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data split into training and testing sets.\n",
            "X_train shape: (1142, 5), y_train shape: (1142,)\n",
            "X_test shape: (286, 5), y_test shape: (286,)\n"
          ]
        }
      ],
      "source": [
        "# Select features and target\n",
        "features = ['Invoice value', 'Payment amount', 'Research team', 'Type of expense', 'Company']\n",
        "target = 'time_to_payment'\n",
        "\n",
        "X = df[features]\n",
        "y = df[target]\n",
        "\n",
        "# Identify categorical and numerical features\n",
        "categorical_features = ['Research team', 'Type of expense', 'Company']\n",
        "numerical_features = ['Invoice value', 'Payment amount']\n",
        "\n",
        "# Preprocessing pipelines for numerical and categorical features\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Create a preprocessor using ColumnTransformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Data split into training and testing sets.\")\n",
        "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Model Training and Evaluation\n",
        "\n",
        "We define a `Pipeline` that first applies the preprocessing steps and then trains a `LinearRegression` model. The model is trained on the training data, and then predictions are made on the test set. Finally, we evaluate the model using Mean Absolute Error (MAE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE), and R-squared (R2).\n",
        "\n",
        "We also test the hypothesis: \"All invoices take ~same time ±1 day.\" This is checked by comparing the MAE to 1 day.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Absolute Error (MAE): 6.68\n",
            "Mean Squared Error (MSE): 64.83\n",
            "Root Mean Squared Error (RMSE): 8.05\n",
            "R-squared (R2): -0.19\n",
            "\n",
            "The model does not strongly support the hypothesis: MAE (6.68 days) is greater than 1 day.\n"
          ]
        }
      ],
      "source": [
        "# Define the model pipeline\n",
        "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                        ('regressor', LinearRegression())])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
        "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
        "print(f\"R-squared (R2): {r2:.2f}\")\n",
        "\n",
        "# Hypothesis testing (simple check based on MAE)\n",
        "if mae <= 1:\n",
        "    print(\"\\nThe model supports the hypothesis: Invoices take approximately the same time (within +/- 1 day).\")\n",
        "else:\n",
        "    print(f\"\\nThe model does not strongly support the hypothesis: MAE ({mae:.2f} days) is greater than 1 day.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 1. Actual vs Predicted Scatter Plot\n",
        "plt.figure(figsize=(7,6))\n",
        "sns.scatterplot(x=y_test, y=y_pred, color='steelblue', alpha=0.7)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
        "plt.title('Actual vs Predicted Time to Payment')\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# 2. Residuals Plot\n",
        "residuals = y_test - y_pred\n",
        "plt.figure(figsize=(7,6))\n",
        "sns.histplot(residuals, kde=True, color='darkorange')\n",
        "plt.title('Distribution of Residuals (Prediction Errors)')\n",
        "plt.xlabel('Residual (Actual - Predicted)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.axvline(0, color='black', linestyle='--')\n",
        "plt.show()\n",
        "\n",
        "# 3. Residuals vs Predicted Values\n",
        "plt.figure(figsize=(7,6))\n",
        "sns.scatterplot(x=y_pred, y=residuals, alpha=0.7)\n",
        "plt.axhline(0, color='red', linestyle='--')\n",
        "plt.title('Residuals vs Predicted Values')\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# 4. Feature Importance (coefficients of linear regression)\n",
        "# Extract coefficients after preprocessing\n",
        "coefs = model.named_steps['regressor'].coef_\n",
        "feature_names = (numerical_features + \n",
        "                 list(model.named_steps['preprocessor']\n",
        "                      .named_transformers_['cat']\n",
        "                      .named_steps['onehot']\n",
        "                      .get_feature_names_out(categorical_features)))\n",
        "\n",
        "coef_df = pd.DataFrame({'Feature': feature_names, 'Coefficient': coefs})\n",
        "coef_df = coef_df.sort_values(by='Coefficient', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(data=coef_df.head(10), x='Coefficient', y='Feature', palette='coolwarm')\n",
        "plt.title('Top 10 Features Influencing Time to Payment')\n",
        "plt.xlabel('Coefficient Value (Impact on Predicted Days)')\n",
        "plt.ylabel('Feature')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
